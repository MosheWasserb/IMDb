{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "colab": {
      "name": "NgramLogisticDima.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MosheWasserb/IMDb/blob/master/NgramLogisticDima.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "s_rfniJMX-s1"
      },
      "source": [
        "### Dataset definition (for CSV file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AW_XPBtJfau3",
        "colab_type": "text"
      },
      "source": [
        "# PyTorch Simple logistic \n",
        "\n",
        "### Moshe Wasserblat <br><br>March 2020"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oUxKvB96favB",
        "colab_type": "text"
      },
      "source": [
        "### Import "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytNZMY1Tfau6",
        "colab_type": "code",
        "outputId": "e28ef90b-e72b-4b82-a901-d8284798933e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "\n",
        "import torch\n",
        "from torchtext import data\n",
        "\n",
        "SEED = 1234\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "TEXT = data.Field(tokenize = 'spacy')\n",
        "LABEL = data.LabelField(dtype = torch.float)\n",
        "\n",
        "from torchtext import datasets\n",
        "\n",
        "train_data, test_data = datasets.IMDB.splits(data.RawField(), LABEL)\n",
        "\n",
        "\n",
        "print(f'Number of training examples: {len(train_data)}')\n",
        "print(f'Number of testing examples: {len(test_data)}')\n",
        "\n",
        "print(vars(train_data.examples[0]))\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples: 25000\n",
            "Number of testing examples: 25000\n",
            "{'text': 'This movie has been poorly received and badly reviewed. The book by Rebecca West was written in 1918, soon after WWI, when shell shock and trauma-induced amnesia were not clich√©s, as the reviewers call it many books and movies later. It is difficult to go back in time and live, as the characters lived, the realities of the time: the war and the horror of the experience of the first war to use lethal gas, the British class system the wife thought all-important, the hopeless spinster, and the lover from the past still seen with the eyes of love being as young and as beautiful as she was 20 years ago.<br /><br />Alan Bates as the amnesiac soldier who \"will die\" if he isn\\'t allowed to see Margaret, the girl of his youthful dreams, builds on the devotion his character showed in \"Far From the Madding Crowd\". Having seen that performance, it is possible to sense his strong romantic attachment to the girl who didn\\'t live up to the family\\'s and society\\'s expectations. Margaret says, \"We quarreled, and as you rowed away, you turned your face away from me.\" So we know that the breakup was something that he instigated, that it brought him shame, but that he forgot the shame in his memory of his time with Margaret. I haven\\'t seen all his films, but in the ones I\\'ve seen, he imparts a strong masculinity, which shines through even in this role as the disabled soldier.<br /><br />I didn\\'t even recognize Ann-Margaret at first and feel that her performance has been underrated. Not having read the book, I wondered whether the child who died was the result of acting on a borderline incestuous feeling between Jenny and Chris, though Jenny does state that she \"is a cousin\". The way Kitty keeps Jenny in the nursery in the hair-drying scene, the fact that Kitty says she always dries her hair in that room seems more a way for Kitty to keep the coals of anger hot than the orientation of the room to the sun, or sentiment about a lost child, and the statement she made that she wished Chris hadn\\'t felt it necessary to preserve the room exactly as it was when the child was alive made her seem uncaring toward the memory of the child. Also, Jenny is shown as living in the house in a subservient role, as high society would have done to a fallen member at the time.<br /><br />Having recently been the recipient of the intense fantasy of a lover (non-sexualin keeping with the mores of the time) from 50 years ago, I couldrelate to Margaret\\'s and her husband\\'s dilemma. I, too, was cast aside because I wasn\\'t good enough for his family, and upon his rediscovery of me via the internet, I was burdened with helping him deal with his still very horrifying Vietnam experiences and a marriage to a woman above his class whom he didn\\'t believe he loved. My husband, like Margaret\\'s was very understanding, but the strain was very real. The lover was finally able to reconcile his real-life situation with his fantasy of loving only me.<br /><br />I thought that it was a good decision to show very little of the reliving of the war experience that was happening in Chris\\'s mind. I thought of \"Mrs. Dalloway\" with the WWI soldier who acts out very violent memories and commits suicide versus Chris\\'s joy in his fantasy of Margaret. In contrast, the actiona of the soldier in \"Mrs. Dalloway\" seems overwrought.<br /><br />Showing that the psychiatrist understood very little of what was happening to Chris underlines what a major problem the whole group faced. Everyone seems to get their life back, but was it the right choice?', 'label': 'pos'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kAfQ7_YOHtST",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random as rn\n",
        "\n",
        "train_texts_full = [e.text for e in train_data]\n",
        "train_labels_full = [e.label for e in train_data]\n",
        "\n",
        "test_texts_full = [e.text for e in test_data]\n",
        "test_labels_full = [e.label for e in test_data]\n",
        "\n",
        "seed=rn.random()\n",
        "rn.seed(seed)\n",
        "rn.shuffle(train_texts_full)\n",
        "rn.seed(seed)\n",
        "rn.shuffle(train_labels_full)\n",
        "\n",
        "seed=rn.random()\n",
        "rn.seed(seed)\n",
        "rn.shuffle(test_texts_full)\n",
        "rn.seed(seed)\n",
        "rn.shuffle(test_labels_full)\n",
        "\n",
        "train_texts = train_texts_full[:100]\n",
        "train_labels = train_labels_full[:100]\n",
        "\n",
        "test_texts = test_texts_full[:1000]\n",
        "test_labels = test_labels_full[:1000]\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbyKUiepVBce",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "673badfc-d112-4a56-d3ce-b08c80231187"
      },
      "source": [
        "type(train_data)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torchtext.datasets.imdb.IMDB"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2nZOTDNOU3W2",
        "colab_type": "text"
      },
      "source": [
        "type(train_data)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JviZCzzUyf-Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Xdict = vars(train_data.examples[0])\n",
        "#XdictText, XdicLabel = list(Xdict.values())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSrLHH-Gvu_G",
        "colab_type": "text"
      },
      "source": [
        "PETER: How do I read train_texts & train_labels from train_data?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jz1ESSlgYMuR"
      },
      "source": [
        "### Simple logistic"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2Uq7BfszYMuS",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euWfiCo1vowX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "6521ded1-62a2-49c4-8016-c09b6389a138"
      },
      "source": [
        "baseline_model = make_pipeline(CountVectorizer(ngram_range=(1,3)), LogisticRegression()).fit(train_texts, train_labels)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYteHnTtvpYh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "baseline_predicted = baseline_model.predict(test_texts)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HoysQKULvrtb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "9b7f26f3-0b1e-48b3-e8e4-19d3c707a4ac"
      },
      "source": [
        "\n",
        "print(classification_report(test_labels, baseline_predicted))"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         neg       0.70      0.64      0.67       489\n",
            "         pos       0.68      0.73      0.70       511\n",
            "\n",
            "   micro avg       0.69      0.69      0.69      1000\n",
            "   macro avg       0.69      0.69      0.69      1000\n",
            "weighted avg       0.69      0.69      0.69      1000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5yHm7Ppyeyk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lnpvwBNKg7x_"
      },
      "source": [
        "### Fine-tune with BERT base on Jay"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3619GCjWg7yA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "50219a33-943d-48ff-af47-7eb6f955e6f0"
      },
      "source": [
        "!pip install transformers\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import transformers as ppb # pytorch transformers\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
            "Requirement already satisfied: tokenizers==0.5.2 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.2)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.38)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.12.27)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.85)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.1)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.5)\n",
            "Requirement already satisfied: botocore<1.16.0,>=1.15.27 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.15.27)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.27->boto3->transformers) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.27->boto3->transformers) (2.8.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEIDnyzDlxpG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('https://github.com/clairett/pytorch-sentiment-classification/raw/master/data/SST2/train.tsv', delimiter='\\t', header=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_PaHYhVvrBzw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_1 = df[:200]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-ifxKI1qg7yK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "704d158d-e40c-4889-b27e-035820efd95b"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>a stirring , funny and finally transporting re...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>apparently reassembled from the cutting room f...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>they presume their audience wo n't sit still f...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>this is a visually stunning rumination on love...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>jonathan parker 's bartleby should have been t...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   0  1\n",
              "0  a stirring , funny and finally transporting re...  1\n",
              "1  apparently reassembled from the cutting room f...  0\n",
              "2  they presume their audience wo n't sit still f...  0\n",
              "3  this is a visually stunning rumination on love...  1\n",
              "4  jonathan parker 's bartleby should have been t...  1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-G3DuU7mDQn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_class, tokenizer_class, pretrained_weights = (ppb.DistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-uncased')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uaoeb31ImPkt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load pretrained model/tokenizer\n",
        "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
        "model = model_class.from_pretrained(pretrained_weights)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t02sEDeumhLb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenized = batch_1[0].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDpC4YFJmhM8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "c4990dd5-2a56-4f8e-b25d-25944964b1a1"
      },
      "source": [
        "tokenized"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       [101, 1037, 18385, 1010, 6057, 1998, 2633, 182...\n",
              "1       [101, 4593, 2128, 27241, 23931, 2013, 1996, 62...\n",
              "2       [101, 2027, 3653, 23545, 2037, 4378, 24185, 10...\n",
              "3       [101, 2023, 2003, 1037, 17453, 14726, 19379, 1...\n",
              "4       [101, 5655, 6262, 1005, 1055, 12075, 2571, 376...\n",
              "                              ...                        \n",
              "6915    [101, 9145, 1010, 7570, 18752, 14116, 1998, 28...\n",
              "6916    [101, 2202, 2729, 2003, 19957, 2864, 2011, 103...\n",
              "6917    [101, 1996, 5896, 4472, 4121, 1010, 3082, 7832...\n",
              "6918    [101, 1037, 5667, 2919, 2143, 2007, 5667, 2561...\n",
              "6919    [101, 1037, 12090, 2135, 2512, 5054, 19570, 23...\n",
              "Name: 0, Length: 6920, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hr9YwIF9oc6d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenized.values\n",
        "max_len = 0\n",
        "for i in tokenized.values:\n",
        "    if len(i) > max_len:\n",
        "        max_len = len(i)\n",
        "\n",
        "padded = np.array([i + [0]*(max_len-len(i)) for i in tokenized.values])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLauePA1pvtQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e6f9fdd5-9697-40d8-a00b-0fd4cfcff608"
      },
      "source": [
        "#masking\n",
        "attention_mask = np.where(padded != 0, 1, 0)\n",
        "attention_mask.shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(200, 54)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "didEfGGBqEm9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Run model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TgPdk_peqH3d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_ids = torch.tensor(padded)  \n",
        "attention_mask = torch.tensor(attention_mask)\n",
        "\n",
        "with torch.no_grad():\n",
        "    last_hidden_states = model(input_ids, attention_mask=attention_mask)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEO7aThSrwkE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features = last_hidden_states[0][:,0,:].numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzfktzJvr3MI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = batch_1[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GXM53o4r7Nf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##Model #2 Train/Test Split\n",
        "train_features, test_features, train_labels, test_labels = train_test_split(features, labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUCDKT61wJJn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "parameters = {'C': np.linspace(0.0001, 100, 20)}\n",
        "grid_search = GridSearchCV(LogisticRegression(), parameters)\n",
        "grid_search.fit(train_features, train_labels)\n",
        "\n",
        "print('best parameters: ', grid_search.best_params_)\n",
        "print('best scrores: ', grid_search.best_score_)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XubVzEeSsrqS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "490f76a0-6299-46a0-8271-e4f744d86ef4"
      },
      "source": [
        "lr_clf = LogisticRegression()\n",
        "lr_clf.fit(train_features, train_labels)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
              "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
              "          tol=0.0001, verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-h3uX1cs038",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "839e336f-e475-4b22-c887-92e8b647b0cc"
      },
      "source": [
        "#Eval\n",
        "lr_clf.score(test_features, test_labels)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.72"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    }
  ]
}